{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be9e34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In Jupyter\n",
    "# !pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd0cf792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In CMD\n",
    "# pip install nltk\n",
    "# NLTK - Natural Language ToolKit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6227ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81b18410",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de35a784",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58fb90b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cc89d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['India', 'Today', 'News', 'breaks', 'the', 'most', 'important', 'stories', 'in', 'and', 'from', 'India', 'and', 'abroad', 'in', 'six', 'sections', '-', 'India', 'News', ',', 'Business', 'News', ',', 'Cinema', 'News', ',', 'Sports', 'News', ',', 'World', 'News', 'and', 'Lifestyle', 'News', '.', 'India', 'News', 'keeps', 'tab', 'of', 'every', 'development', 'in', 'all', 'parts', 'of', 'India', '.', 'Business', 'News', 'has', 'the', 'latest', 'business', 'updates', 'from', 'India', 'and', 'abroad', '.', 'Cinema', 'News', 'tracks', 'the', 'latest', 'from', 'Bollywood', ',', 'Hollywood', 'and', 'the', 'South', 'film', 'industries', 'and', 'TV', 'channels', '.', 'Sports', 'News', 'has', 'all', 'the', 'sports', 'from', 'India', 'and', 'abroad', 'with', 'a', 'special', 'focus', 'on', 'cricket', '.', 'Lifestyle', 'News', 'presents', 'developments', 'that', 'impact', 'one', \"'s\", 'lifestyle', '.', 'World', 'News', 'makes', 'sense', 'of', 'news', 'across', 'the', 'world', 'and', 'its', 'impact', 'on', 'India', '.']\n",
      "121\n"
     ]
    }
   ],
   "source": [
    "text = \"India Today News breaks the most important stories in and from India and abroad in \\\n",
    "six sections - India News, Business News, Cinema News, Sports News, World News and Lifestyle \\\n",
    "News. India News keeps tab of every development in all parts of India. Business News has the \\\n",
    "latest business updates from India and abroad. Cinema News tracks the latest from Bollywood, \\\n",
    "Hollywood and the South film industries and TV channels. Sports News has all the sports from \\\n",
    "India and abroad with a special focus on cricket. Lifestyle News presents developments that \\\n",
    "impact one's lifestyle. World News makes sense of news across the world and its impact on \\\n",
    "India.\"\n",
    "\n",
    "words = word_tokenize(text)\n",
    "print(words)\n",
    "print(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b7b382e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['India', 'Today', 'News', 'breaks', 'the', 'most', 'important', 'stories', 'in', 'and', 'from', 'India', 'and', 'abroad', 'in', 'six', 'sections', '-', 'India', 'News', ',', 'Business', 'News', ',', 'Cinema', 'News', ',', 'Sports', 'News', ',', 'World', 'News', 'and', 'Lifestyle', 'News.', 'India', 'News', 'keeps', 'tab', 'of', 'every', 'development', 'in', 'all', 'parts', 'of', 'India.', 'Business', 'News', 'has', 'the', 'latest', 'business', 'updates', 'from', 'India', 'and', 'abroad.', 'Cinema', 'News', 'tracks', 'the', 'latest', 'from', 'Bollywood', ',', 'Hollywood', 'and', 'the', 'South', 'film', 'industries', 'and', 'TV', 'channels.', 'Sports', 'News', 'has', 'all', 'the', 'sports', 'from', 'India', 'and', 'abroad', 'with', 'a', 'special', 'focus', 'on', 'cricket.', 'Lifestyle', 'News', 'presents', 'developments', 'that', 'impact', 'one', \"'s\", 'lifestyle.', 'World', 'News', 'makes', 'sense', 'of', 'news', 'across', 'the', 'world', 'and', 'its', 'impact', 'on', 'India', '.']\n",
      "115\n"
     ]
    }
   ],
   "source": [
    "words1 = word_tokenize(text,preserve_line=True)\n",
    "print(words1)\n",
    "print(len(words1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92bdd52a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['of', 'Business', 'Bollywood', 'channels', 'world', 'from', 'Hollywood', 'sports', 'across', 'development', 'makes', 'developments', 'tracks', 'impact', 'sections', 'Sports', 'six', '-', 'Lifestyle', 'business', 'lifestyle', 'special', 'industries', \"'s\", 'has', 'focus', ',', 'South', 'a', 'keeps', 'latest', 'one', 'World', 'updates', 'Today', 'India', 'breaks', '.', 'on', 'sense', 'its', 'and', 'Cinema', 'every', 'the', 'film', 'tab', 'that', 'important', 'in', 'TV', 'cricket', 'news', 'with', 'News', 'abroad', 'parts', 'all', 'stories', 'presents', 'most']\n",
      "61\n"
     ]
    }
   ],
   "source": [
    "unique_words = list(set(words))\n",
    "print(unique_words)\n",
    "print(len(unique_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91582f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['India Today News breaks the most important stories in and from India and abroad in six sections - India News, Business News, Cinema News, Sports News, World News and Lifestyle News.', 'India News keeps tab of every development in all parts of India.', 'Business News has the latest business updates from India and abroad.', 'Cinema News tracks the latest from Bollywood, Hollywood and the South film industries and TV channels.', 'Sports News has all the sports from India and abroad with a special focus on cricket.', \"Lifestyle News presents developments that impact one's lifestyle.\", 'World News makes sense of news across the world and its impact on India.']\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "sentences = sent_tokenize(text)\n",
    "print(sentences)\n",
    "print(len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd8fedb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sports News has all the sports from India and abroad with a special focus on cricket.', 'India News keeps tab of every development in all parts of India.', 'World News makes sense of news across the world and its impact on India.', 'Cinema News tracks the latest from Bollywood, Hollywood and the South film industries and TV channels.', \"Lifestyle News presents developments that impact one's lifestyle.\", 'India Today News breaks the most important stories in and from India and abroad in six sections - India News, Business News, Cinema News, Sports News, World News and Lifestyle News.', 'Business News has the latest business updates from India and abroad.']\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "unique_sent = list(set(sentences))\n",
    "print(unique_sent)\n",
    "print(len(unique_sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ec917e",
   "metadata": {},
   "source": [
    "### StopWords\n",
    "According to NLTK, stopwords are the words which we need to remove as a text preprocessing step from our text based data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12b4f5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
      "179\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "sw = stopwords.words('english')\n",
    "print(sw)\n",
    "print(len(sw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ebc9c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tiger', 'is', 'crossing', 'the', 'road', 'but', 'it', 'is', 'tired', '.']\n",
      "['Tiger', 'crossing', 'road', 'tired', '.']\n"
     ]
    }
   ],
   "source": [
    "text = \"Tiger is crossing the road but it is tired.\"\n",
    "wt = word_tokenize(text)\n",
    "print(wt)\n",
    "filtered_text = [i for i in wt if i not in sw]\n",
    "print(filtered_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d425d517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Business', 'Bollywood', 'channels', 'world', 'Hollywood', 'sports', 'across', 'development', 'makes', 'developments', 'tracks', 'impact', 'sections', 'Sports', 'six', '-', 'Lifestyle', 'business', 'lifestyle', 'special', 'industries', \"'s\", 'focus', ',', 'South', 'keeps', 'latest', 'one', 'World', 'updates', 'Today', 'India', 'breaks', '.', 'sense', 'Cinema', 'every', 'film', 'tab', 'important', 'TV', 'cricket', 'news', 'News', 'abroad', 'parts', 'stories', 'presents']\n"
     ]
    }
   ],
   "source": [
    "filetered_news = [i for i in unique_words if i not in sw]\n",
    "print(filetered_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d1621a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['au', 'aux', 'avec', 'ce', 'ces', 'dans', 'de', 'des', 'du', 'elle', 'en', 'et', 'eux', 'il', 'ils', 'je', 'la', 'le', 'les', 'leur', 'lui', 'ma', 'mais', 'me', 'même', 'mes', 'moi', 'mon', 'ne', 'nos', 'notre', 'nous', 'on', 'ou', 'par', 'pas', 'pour', 'qu', 'que', 'qui', 'sa', 'se', 'ses', 'son', 'sur', 'ta', 'te', 'tes', 'toi', 'ton', 'tu', 'un', 'une', 'vos', 'votre', 'vous', 'c', 'd', 'j', 'l', 'à', 'm', 'n', 's', 't', 'y', 'été', 'étée', 'étées', 'étés', 'étant', 'étante', 'étants', 'étantes', 'suis', 'es', 'est', 'sommes', 'êtes', 'sont', 'serai', 'seras', 'sera', 'serons', 'serez', 'seront', 'serais', 'serait', 'serions', 'seriez', 'seraient', 'étais', 'était', 'étions', 'étiez', 'étaient', 'fus', 'fut', 'fûmes', 'fûtes', 'furent', 'sois', 'soit', 'soyons', 'soyez', 'soient', 'fusse', 'fusses', 'fût', 'fussions', 'fussiez', 'fussent', 'ayant', 'ayante', 'ayantes', 'ayants', 'eu', 'eue', 'eues', 'eus', 'ai', 'as', 'avons', 'avez', 'ont', 'aurai', 'auras', 'aura', 'aurons', 'aurez', 'auront', 'aurais', 'aurait', 'aurions', 'auriez', 'auraient', 'avais', 'avait', 'avions', 'aviez', 'avaient', 'eut', 'eûmes', 'eûtes', 'eurent', 'aie', 'aies', 'ait', 'ayons', 'ayez', 'aient', 'eusse', 'eusses', 'eût', 'eussions', 'eussiez', 'eussent']\n",
      "157\n"
     ]
    }
   ],
   "source": [
    "sw = stopwords.words('french')\n",
    "print(sw)\n",
    "print(len(sw))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738e2ff7",
   "metadata": {},
   "source": [
    "### Punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "44817913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "punc = string.punctuation\n",
    "print(punc)\n",
    "type(punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5e2b6cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Business', 'Bollywood', 'channels', 'world', 'Hollywood', 'sports', 'across', 'development', 'makes', 'developments', 'tracks', 'impact', 'sections', 'Sports', 'six', '-', 'Lifestyle', 'business', 'lifestyle', 'special', 'industries', \"'s\", 'focus', ',', 'South', 'keeps', 'latest', 'one', 'World', 'updates', 'Today', 'India', 'breaks', '.', 'sense', 'Cinema', 'every', 'film', 'tab', 'important', 'TV', 'cricket', 'news', 'News', 'abroad', 'parts', 'stories', 'presents']\n"
     ]
    }
   ],
   "source": [
    "print(filetered_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ce2f4f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Business', 'Bollywood', 'channels', 'world', 'Hollywood', 'sports', 'across', 'development', 'makes', 'developments', 'tracks', 'impact', 'sections', 'Sports', 'six', 'Lifestyle', 'business', 'lifestyle', 'special', 'industries', \"'s\", 'focus', 'South', 'keeps', 'latest', 'one', 'World', 'updates', 'Today', 'India', 'breaks', 'sense', 'Cinema', 'every', 'film', 'tab', 'important', 'TV', 'cricket', 'news', 'News', 'abroad', 'parts', 'stories', 'presents']\n"
     ]
    }
   ],
   "source": [
    "punc_removed = [i for i in filetered_news if i not in punc]\n",
    "print(punc_removed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe25e332",
   "metadata": {},
   "source": [
    "### Text Preprocessing Steps \n",
    "\n",
    "1) Conversion to lower case<br>\n",
    "2) Word Tokenization<br>\n",
    "2) Stop Words Removal<br>\n",
    "3) Punctutaion Removal<br>\n",
    "5) Stemming or Lemmatization<br>\n",
    "6) Digits removal<br>\n",
    "\n",
    "7) Vectorization<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eae77ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "s = \"hello World\"\n",
    "print(s.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c824ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
